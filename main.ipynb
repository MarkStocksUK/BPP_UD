{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2633ed",
   "metadata": {},
   "source": [
    "![Cover Sheet Image](BP0289232_CoverSheet.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d146ad76",
   "metadata": {},
   "source": [
    "# <b>Project overview</b>\n",
    "- To gain insight into customer opinion of the company using Trustpilot.\n",
    "- To acheive this we will scrape the company pages on Trustpilot for *individual reviews text*, *individual review scores* and *date of review*.\n",
    "\n",
    "---\n",
    "\n",
    "### <b>Ensure that scrape.py, structure.py and sentiment_and_topics.py are placed in the same directory as main.ipynb</b>\n",
    "\n",
    "---\n",
    "\n",
    "<b>Outline of the process</b>\n",
    "\n",
    "At a high level the process is broken out into 3 sections\n",
    "<ul>\n",
    "<li>Scraping</li>\n",
    "<li>Structuring</li>\n",
    "<li>Sentiments and topics</li>\n",
    "</ul>\n",
    "When the main code is run the user is asked to choose whether to scrape Trustpilot or use any cached files in the pages directory.\n",
    "\n",
    "<ul>\n",
    "<li>Parameters are hardcoded to scrape The AA's Trustpilot page for the last 30 days</li>\n",
    "<li>Ask the user if they wish to scrape the site or use the cached pages in the pages folder</li>\n",
    "<li>If the user wants to scrape</li>\n",
    "    <ul>\n",
    "    <b>Scraping process</b>\n",
    "    <li>Check if we can are allowed to scrape the url by reading the Robots.txt file</li>\n",
    "    <li>Start a while loop</li>\n",
    "        <ul>\n",
    "        <li>Build the URL for page to scrape</li>\n",
    "        <li>Try to scrape that page</li>\n",
    "        <li>If we get a 200 response</li>\n",
    "            <ul>\n",
    "            <li>If it's the first page, get the overall rating</li>\n",
    "            <li>Save the page content to the pages folder</li>\n",
    "            <li>Increment the page number</li>\n",
    "            </ul>\n",
    "        <li>If we get a rate limit message</li>\n",
    "            <ul>\n",
    "            <li>Stop fetching pages and exit the while loop</li>\n",
    "            </ul>\n",
    "        <li>If we receive no content</li>\n",
    "            <ul>\n",
    "            <li>Stop fetching pages and exit the while loop</li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </ul>\n",
    "\n",
    "<li><b>Structuring process</b></li>\n",
    "<li>For each html file in the pages directory</li>\n",
    "    <ul>\n",
    "    <li>find the reviews</li>\n",
    "        <ul>\n",
    "        <li>for each review</li>\n",
    "            <li>get the review id</li>\n",
    "            <li>get the review text</li>\n",
    "            <li>get the review rating</li>\n",
    "            <li>get the source of the review</li>\n",
    "            <li>get the date of the experience</li>\n",
    "            <li>get the date of pubication</li>\n",
    "            <li>add these to a dataframe</li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "<li>with the complete dataframe change the source codes to something more understandable</li>\n",
    "<li>save the dataframe as a csv file in the csv files directory</li>\n",
    "<br>\n",
    "<li><b>Sentiment and topic process</b></li>                \n",
    "<li>Perform sentiment analysis on the reviews text</li>\n",
    "<li>Save the new dataframe as a csv file to the csv files directory/li>\n",
    "<li>Create metrics for the reviews, split by source and at an overall level</li>\n",
    "    <ul>\n",
    "    <li>Count of reviews</li>\n",
    "    <li>mean average rating</li>\n",
    "    <li>mode average rating</li>\n",
    "    <li>Average polarity score</li>\n",
    "    <li>Average subjectivity score</li>\n",
    "    <li>Positive review count and percentage</li>\n",
    "    <li>Negative review count and percentage</li>\n",
    "    </ul>\n",
    "<li>Metrics are saved in the outputs directory</li>\n",
    "<li>Reviews are filtered to only include the negative reviews (sentiment less than -0.25 and rating less than 3)</li>\n",
    "<li>The review text is then cleaned and English stop words as well as AA and Car are removed</li>\n",
    "<li>A word cloud image is then created of the negative reviews</li>\n",
    "<li>Next the text is vectorised based on the frequency of each word</li>\n",
    "<li>Topic modelling is then performed using LDA</li>\n",
    "<li>The top 5 words for each topic will then be prined on screen</li>\n",
    "<li>An interactive lda_visualisation.html file will be saved in the outputs directory for further topic analysis</li>\n",
    "<li>A timeline graph of the daily mean average review score will be displayed and a copy saved in the outputs directory</li>\n",
    "</ul>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main module\n",
    "\n",
    "\n",
    "# Importing libraries\n",
    "# Standard library imports\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "# Third party imports\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from urllib.robotparser import RobotFileParser\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "\n",
    "# Local application/library imports - assumes this script is in the same directory as the modules\n",
    "import scrape\n",
    "import structure\n",
    "import sentiment_and_topics\n",
    "\n",
    "# Function to clear a log file\n",
    "def clear_this_log(logfile_name):\n",
    "    \"\"\"\n",
    "    Clear the given log file.\n",
    "    \"\"\"\n",
    "    with open(logfile_name, 'w'):\n",
    "        pass\n",
    "\n",
    "# Function to configure logging for the script\n",
    "def configure_logging(logfile_name, clear_log):\n",
    "    \"\"\"\n",
    "    Configures logging for the script.\n",
    "    Args:\n",
    "    logfile_name (str): The name of the log file.\n",
    "    clear_log (bool): If True, clears the log file at the start of the script.\n",
    "\n",
    "    Returns:\n",
    "    logger (logging.Logger): Configured logger instance.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        filename=logfile_name,\n",
    "        level=logging.INFO,  # Log level\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'  # Log format\n",
    "    )\n",
    "\n",
    "    # Create a logger\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    if clear_log:\n",
    "        logger.info(\"Clearing log file at the start of the script.\")\n",
    "        clear_this_log(logfile_name)\n",
    "\n",
    "    # Assert statement for testing purposes\n",
    "    assert logger.hasHandlers(), \"Logger should have handlers\"\n",
    "\n",
    "    return logger        \n",
    "\n",
    "# Function to get user input for scraping or using cached pages\n",
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Gets user input for whether to scrape or use cached pages.\n",
    "    \n",
    "    Returns:\n",
    "    user_input (str): User input ('scrape' or 'cache').\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Do you want to scrape or use cached pages? (scrape/cache): \").strip().lower()\n",
    "        if user_input in [\"scrape\", \"cache\"]:\n",
    "            return user_input\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'scrape' or 'cache'.\")\n",
    "\n",
    "\n",
    "# Main code\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the script.\n",
    "    It configures logging, gets user input, and calls the appropriate functions for scraping, structuring data,\n",
    "    and modelling sentiment and topics.\n",
    "    \"\"\"\n",
    "    # Set up the log file name and whether to clear it\n",
    "    logfile_name = 'main.log'\n",
    "    clear_log = True # True = clear the log file. False = keep the existing log file and append to it.\n",
    "\n",
    "    # Configure logging\n",
    "    logger = configure_logging(logfile_name, clear_log)\n",
    "    \n",
    "    logger.info(\"Script execution started.\")    \n",
    "\n",
    "    # Get user input for scraping or using cached pages\n",
    "    scrape_or_cache = get_user_input()\n",
    "    logger.debug(f\"User input for scraping or caching: {scrape_or_cache}\")\n",
    "\n",
    "    if scrape_or_cache == \"scrape\":\n",
    "        logger.info(\"Scraping pages\")\n",
    "        scrape.scrape()\n",
    "        logger.info(\"Structuring data\")\n",
    "        structure.structure()\n",
    "        logger.info(\"Modelling sentiment and identifying topics\")\n",
    "        sentiment_and_topics.sentiment_and_topics()\n",
    "    elif scrape_or_cache == \"cache\":\n",
    "        logger.info(\"Using cached pages\")\n",
    "        logger.info(\"Structuring data\")\n",
    "        structure.structure()\n",
    "        logger.info(\"Modelling sentiment and identifying topics\")\n",
    "        sentiment_and_topics.sentiment_and_topics()\n",
    "\n",
    "    # close the logger\n",
    "    logger.info(\"Script execution completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if the script is being run directly\n",
    "    # If so, call the main function to start the program\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "App_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
